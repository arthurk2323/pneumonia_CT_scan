{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f164d0da-af26-4a8c-a11f-2fc1222af931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/arthur/Documents/Flatiron/phase_4/Project/pneumonia_CT_scan\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc0b1887-aa0d-443e-a9e2-c327dff5bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b16ff4d8-0695-481b-abde-f0aa5b25e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/split/train'\n",
    "val_dir = 'data/split/val'\n",
    "test_dir = 'data/split/test'\n",
    "\n",
    "train_pneu = train_dir + '/PNEUMONIA'\n",
    "val_pneu = val_dir + '/PNEUMONIA'\n",
    "test_pneu = test_dir + '/PNEUMONIA'\n",
    "train_non_pneu = train_dir + '/NORMAL'\n",
    "val_non_pneu = val_dir + '/NORMAL'\n",
    "test_non_pneu = test_dir + '/NORMAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b3268a-9cd1-4cca-ba38-fa815973be47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2564 pneumonia images in the training set\n",
      "There are 855 pneumonia images in the validation set\n",
      "There are 854 pneumonia images in the testing set\n",
      "There are 950 non-pneumonia images in the training set\n",
      "There are 317 non-pneumonia images in the validation set\n",
      "There are 316 non-pneumonia images in the testing set\n"
     ]
    }
   ],
   "source": [
    "print('There are', len(os.listdir(train_pneu)), 'pneumonia images in the training set')\n",
    "print('There are', len(os.listdir(val_pneu)), 'pneumonia images in the validation set')\n",
    "print('There are', len(os.listdir(test_pneu)), 'pneumonia images in the testing set')\n",
    "print('There are', len(os.listdir(train_non_pneu)), 'non-pneumonia images in the training set')\n",
    "print('There are', len(os.listdir(val_non_pneu)), 'non-pneumonia images in the validation set')\n",
    "print('There are', len(os.listdir(test_non_pneu)), 'non-pneumonia images in the testing set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77a03fa2-9d28-4527-9bd0-8933e56036fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3514 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Found 1170 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Get all the data in the directory data/train (2564+950 images), and reshape them\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_dir, \n",
    "        target_size=(64, 64), batch_size=32)\n",
    "\n",
    "# Get all the data in the directory data/val (855+317 images), and reshape them\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_dir, \n",
    "        target_size=(64, 64), batch_size=32)\n",
    "\n",
    "# Get all the data in the directory data/test (854+316 images), and reshape them\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_dir, \n",
    "        target_size=(64, 64), batch_size=32)\n",
    "\n",
    "# Create the datasets\n",
    "train_images, train_labels = next(train_generator)\n",
    "val_images, val_labels = next(val_generator)\n",
    "test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617db723-e7c2-48a9-94a9-9e2ec411feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(train_images))\n",
    "print(np.shape(train_labels))\n",
    "print(np.shape(val_images))\n",
    "print(np.shape(val_labels))\n",
    "print(np.shape(test_images))\n",
    "print(np.shape(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd24a8f5-04bd-4a77-9673-19fd8c814e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator.class_indices)\n",
    "print(val_generator.class_indices)\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e6d301-5420-49ea-a90c-ac38b074ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n",
    "print(val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6bfdaa-20d6-44b9-9793-9b2c28435360",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_labels[:,0], (train_images.shape[0],1))\n",
    "test_y = np.reshape(test_labels[:,0], (test_images.shape[0],1))\n",
    "val_y = np.reshape(val_labels[:,0], (val_images.shape[0],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedf1181-cc30-42d4-94ff-79644f2b724a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dummy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd35d25-8c38-4654-9280-a7356acbf3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61229fd-8146-4291-a70c-5e1547a1eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf.score(train_images,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f8706e-6bde-4686-8f4b-67fa74fc0321",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf.score(val_images,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23efd52a-0981-4dca-a605-71636d92f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf.score(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4e4c37-fabf-4dfc-837a-0c2e1b57b4e9",
   "metadata": {},
   "source": [
    "## Model 1: Neural Network without Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04239296-da87-4854-bd09-cecbbf5e1955",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model1 = models.Sequential()\n",
    "model1.add(layers.Dense(2, activation='relu', input_shape=(12288,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59655579-1d90-471f-bafe-1b1340aa5520",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history1 = model1.fit(train_img,\n",
    "                     train_y,\n",
    "                     epochs=50,\n",
    "                     batch_size=32,\n",
    "                     validation_data=(val_img, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c55bd9-c8fc-4ea5-b4cf-3982bae0aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = model1.evaluate(train_img, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0df9dd-6e59-46f1-866d-23c94e5a7222",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = model1.evaluate(test_img, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1d772-dd56-44e3-b261-c981c7448c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b9cbc-dca8-4131-9a0e-8804c10f49b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75478279-dd9a-4eff-be4a-33f93a56e472",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 2: Neural Network with Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c436d2-4f9e-48c9-8789-bea18f06aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.Dense(200, activation='relu', input_shape=(12288,)))\n",
    "model2.add(layers.Dense(100, activation='relu'))\n",
    "model2.add(layers.Dense(50, activation='relu'))\n",
    "model2.add(layers.Dense(25, activation='relu'))\n",
    "model2.add(layers.Dense(7, activation='relu'))\n",
    "model2.add(layers.Dense(5, activation='relu'))\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b048cfe2-0427-44f1-974d-00906937ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(train_img,\n",
    "                     train_y,\n",
    "                     epochs=50,\n",
    "                     batch_size=32,\n",
    "                     validation_data=(val_img, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b66cadc-bab7-4163-a338-03623629d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = model2.evaluate(train_img, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dc1768-3e76-479c-b01d-8780d402a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = model2.evaluate(test_img, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ddb25-317a-4ca9-84aa-5cc803f54117",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a751347c-b375-43ae-841f-6a4cf5f8ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7aea3d-f65d-4a2e-8976-c8b78f98b8e5",
   "metadata": {},
   "source": [
    "## Model 3: Neural Network with Dense and Drop Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3eae62-a0ea-4201-95c5-8c1d38ee1fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model3 = models.Sequential()\n",
    "model3.add(layers.Dense(200, activation='relu', input_shape=(12288,)))\n",
    "model3.add(layers.Dense(100, activation='relu'))\n",
    "model3.add(layers.Dropout(0.3))\n",
    "model3.add(layers.Dense(50, activation='relu'))\n",
    "model3.add(layers.Dense(25, activation='relu'))\n",
    "model3.add(layers.Dropout(0.3))\n",
    "model3.add(layers.Dense(7, activation='relu'))\n",
    "model3.add(layers.Dense(5, activation='relu'))\n",
    "model3.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f4e1b-8f99-48a7-8bb4-7374b40790ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history3 = model3.fit(train_img,\n",
    "                     train_y,\n",
    "                     epochs=50,\n",
    "                     batch_size=32,\n",
    "                     validation_data=(val_img, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652dfbc-3d7e-49a6-89fa-aada877c803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = model3.evaluate(train_img, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fd84da-10d2-47ea-8150-660e30562ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = model3.evaluate(test_img, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5184f-26f8-4593-b502-0d8be830bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a8d6a-3018-4b73-8db7-35d882764bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef87d1fc-59a0-4644-9119-8e4519db6e07",
   "metadata": {},
   "source": [
    "## Model 4: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294e361f-439e-455c-be3c-aadc573c2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = models.Sequential()\n",
    "model4.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(64 ,64,  3)))\n",
    "model4.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model4.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "model4.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model4.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model4.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model4.add(layers.Flatten())\n",
    "model4.add(layers.Dense(64, activation='relu'))\n",
    "model4.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6f453f-bec4-4642-9112-670c330d6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history4 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_images, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c11ac8-e4eb-40a5-920c-c1dd9ba99b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = model.evaluate(train_images, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2a36e-6e62-4cc1-bd39-ac170d2376d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = model.evaluate(test_images, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4159de-9d64-48a7-9715-d3e96dbea26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f91e0-ed52-48b2-9735-707d5fd6db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4485334a-3348-4e17-8106-28dd1cffc0f3",
   "metadata": {},
   "source": [
    "## Overampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a546ef5a-5898-4366-b4fa-b8c5f142a3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "main_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
