{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d07079b6-13f5-493d-ac0a-f4c87599265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import cv2\n",
    "import os \n",
    "from keras import Sequential\n",
    "from keras.layers import Flatten,Dense,BatchNormalization,Dropout,LeakyReLU,GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.applications import ResNet50V2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "\n",
    "\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dropout, Flatten, Dense \n",
    "from keras import applications \n",
    "from keras.utils.np_utils import to_categorical \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import math \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5168bd17-fc32-411b-9580-5e2a95107da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/split2/train/\"\n",
    "test_path = \"data/split2/test/\"\n",
    "val_path = \"data/split2/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c51a27-c4b4-4397-8810-366b07b80954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/miafryer/Documents/flatiron/pneumonia_CT_scan\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8583ed-b982-496f-8ee2-e89b6eb4ed24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1668"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_bacteria = [file for file in os.listdir(train_path+'BACTERIA') if file.endswith('.jpeg')]\n",
    "len(imgs_bacteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c504d2-4ed2-4812-a512-06fc3d5265fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3514 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_path, target_size=(64, 64), batch_size = 3514, class_mode='categorical') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4707e005-4696-4f64-9e03-a4baf50b9c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1171 images belonging to 3 classes.\n",
      "Found 1171 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_path, \n",
    "        target_size=(64, 64), \n",
    "        batch_size = 1171,\n",
    "        class_mode='categorical') \n",
    "\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_path, \n",
    "        target_size=(64, 64),\n",
    "        batch_size = 1171,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8ee411-d4e7-40a9-99ce-b762f25dfc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BACTERIA': 0, 'NORMAL': 1, 'VIRUS': 2}\n",
      "{'BACTERIA': 0, 'NORMAL': 1, 'VIRUS': 2}\n",
      "{'BACTERIA': 0, 'NORMAL': 1, 'VIRUS': 2}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)\n",
    "print(val_generator.class_indices)\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be54a701-ba72-49c0-b7b5-029705bc722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ebd0a-0b5a-4406-a619-907c57698797",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_images.reshape((-1, 28, 28, 1))\n",
    "X_test = X_test.reshape(X_test.shape[0], *(28, 28, 1))\n",
    "X_validate = X_validate.reshape(X_validate.shape[0], *(28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36ec457c-9e7e-4e0d-a1dd-b88b8e8659f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 3514\n",
      "Number of testing samples: 1171\n",
      "Number of validation samples: 1171\n",
      "train_images shape: (3514, 64, 64, 3)\n",
      "train_labels shape: (3514, 3)\n",
      "test_images shape: (1171, 64, 64, 3)\n",
      "test_labels shape: (1171, 3)\n",
      "val_images shape: (1171, 64, 64, 3)\n",
      "val_labels shape: (1171, 3)\n"
     ]
    }
   ],
   "source": [
    "m_train = train_images.shape[0]\n",
    "num_px = train_images.shape[1]\n",
    "m_test = test_images.shape[0]\n",
    "m_val = val_images.shape[0]\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "print (\"Number of validation samples: \" + str(m_val))\n",
    "print (\"train_images shape: \" + str(train_images.shape))\n",
    "print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "print (\"test_images shape: \" + str(test_images.shape))\n",
    "print (\"test_labels shape: \" + str(test_labels.shape))\n",
    "print (\"val_images shape: \" + str(val_images.shape))\n",
    "print (\"val_labels shape: \" + str(val_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "733e2e53-ea4c-4697-bb5b-45f16156d8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3514, 12288)\n",
      "(1171, 12288)\n",
      "(1171, 12288)\n"
     ]
    }
   ],
   "source": [
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n",
    "print(val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30f8cf93-889c-4baf-b499-777419e2c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_classes = train_generator.classes \n",
    "num_classes_train = len(train_generator.class_indices) \n",
    "#train_labels_cat = to_categorical(train_classes, num_classes=num_classes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5873a870-e0eb-4eb4-99f0-fd7cecca7a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc74434b-2b78-4804-b192-7e64941ba289",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "model.add(Flatten(input_shape=train_img.shape[1:])) \n",
    "model.add(Dense(100, activation=keras.layers.LeakyReLU(alpha=0.3))) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(50, activation=keras.layers.LeakyReLU(alpha=0.3))) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(num_classes_train, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "   optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "   metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "737db956-569c-44a6-a868-1bcd5d303f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 0.7479 - acc: 0.6827 - val_loss: 0.7567 - val_acc: 0.6524\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 0.7398 - acc: 0.6838 - val_loss: 0.8690 - val_acc: 0.6678\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 1s 8ms/step - loss: 0.7109 - acc: 0.6938 - val_loss: 0.6573 - val_acc: 0.7190\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 0.7326 - acc: 0.6941 - val_loss: 0.6904 - val_acc: 0.7088\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 0.6936 - acc: 0.7012 - val_loss: 0.6059 - val_acc: 0.7344\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 1s 8ms/step - loss: 0.6958 - acc: 0.6929 - val_loss: 0.6699 - val_acc: 0.7088\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 0.6936 - acc: 0.7040 - val_loss: 0.7447 - val_acc: 0.6772\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 1s 8ms/step - loss: 0.6804 - acc: 0.7072 - val_loss: 0.6086 - val_acc: 0.7412\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 1s 8ms/step - loss: 0.6618 - acc: 0.7143 - val_loss: 0.8658 - val_acc: 0.6302\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 1s 8ms/step - loss: 0.6695 - acc: 0.7134 - val_loss: 0.5769 - val_acc: 0.7301\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_img, train_labels, \n",
    "   epochs=10,\n",
    "   batch_size=50, \n",
    "   validation_data=(val_img , val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00b331ff-2f22-4ea9-a92f-ae8313b3fb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 0.6048 - acc: 0.7259\n"
     ]
    }
   ],
   "source": [
    "(eval_loss, eval_accuracy) = model.evaluate( \n",
    "    test_img , test_labels, batch_size=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed69fbee-ced7-49b2-8c31-5d82d2c2e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = model.predict(test_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "feec75e6-654f-4ea8-93c5-3be6d46773db",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_test_labels = pd.DataFrame(test_labels,columns= ('BACTERIA', 'NORMAL', 'VIRUS')).idxmax(axis=1)\n",
    "categorical_preds = pd.DataFrame(y_hat_test,columns= ('BACTERIA', 'NORMAL', 'VIRUS')).idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "204eb09a-e079-4599-9389-77b9cfba3bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(categorical_test_labels,categorical_preds,labels=['BACTERIA', 'NORMAL' ,'VIRUS'] )\n",
    "sns.heatmap(cnf_matrix , annot=True, fmt=\"d\",cmap=\"YlGnBu\",xticklabels=['BACTERIA', 'NORMAL' ,'VIRUS'], yticklabels=['BACTERIA', 'NORMAL' ,'VIRUS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16f9e40d-70d4-4204-82ad-702b1fec3b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BACTERIA       0.67      0.93      0.78       556\n",
      "      NORMAL       0.90      0.85      0.87       316\n",
      "       VIRUS       0.67      0.22      0.33       299\n",
      "\n",
      "    accuracy                           0.73      1171\n",
      "   macro avg       0.74      0.67      0.66      1171\n",
      "weighted avg       0.73      0.73      0.69      1171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_metrics= classification_report(categorical_test_labels,categorical_preds, target_names=['BACTERIA', 'NORMAL' ,'VIRUS'])\n",
    "print(classification_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749e46b6-b559-482b-bda9-2c59bd034530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72f250ce-e757-42ff-b5fc-0d42dacdad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model2 = models.Sequential()\n",
    "#model2.add(Flatten(input_shape=train_img.shape[1:])) \n",
    "model2.add(layers.Dense(20, activation='relu', input_shape=(12288,)))\n",
    "model2.add(layers.Dense(7, activation='relu'))\n",
    "model2.add(layers.Dense(5, activation='relu'))\n",
    "model2.add(layers.Dense(num_classes_train, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e164613-b2d5-4720-83a4-0306753e49bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 1.1344 - accuracy: 0.3497 - val_loss: 1.0746 - val_accuracy: 0.4936\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 1.0677 - accuracy: 0.4736 - val_loss: 1.0564 - val_accuracy: 0.4791\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 1.0479 - accuracy: 0.4803 - val_loss: 1.0311 - val_accuracy: 0.4791\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 1.0294 - accuracy: 0.4918 - val_loss: 1.0508 - val_accuracy: 0.5278\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 1.0163 - accuracy: 0.5244 - val_loss: 0.9979 - val_accuracy: 0.5687\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.9918 - accuracy: 0.5761 - val_loss: 0.9819 - val_accuracy: 0.5594\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.9497 - accuracy: 0.6233 - val_loss: 1.0073 - val_accuracy: 0.4321\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.9087 - accuracy: 0.6315 - val_loss: 0.8937 - val_accuracy: 0.6328\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.8540 - accuracy: 0.6618 - val_loss: 0.8288 - val_accuracy: 0.6618\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.8318 - accuracy: 0.6537 - val_loss: 0.8294 - val_accuracy: 0.6541\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(train_img, train_labels, \n",
    "   epochs=10,\n",
    "   batch_size=50, \n",
    "   validation_data=(val_img,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "885d4a9c-9e70-4e3a-a9b7-c6a22a42e989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 20)                245780    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 7)                 147       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 245,985\n",
      "Trainable params: 245,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e8e27-0fef-4c14-a2b9-122b36bb37f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737f634-5586-40c4-baa5-af92da56850a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66ed02f-9619-4372-8c4d-1df4a016a9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e938bac9-77fd-41a2-bb35-3259af5436e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709ed202-d9bf-4a32-aa36-c2aa44faaa78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7494b-035a-41b9-bfe2-0019f2aaabfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(include_top = False, weights = 'imagenet', input_shape = (32,32,3), classes = y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e316f7e-65ac-477e-ba00-210e7beb0ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5265b2f6-0ae1-4cc5-882f-7a5436290a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5999ff41-90d0-40ab-bb2b-0ba1bbf71701",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = models.Sequential()\n",
    "model3.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(64 ,64,  3)))\n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model3.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model3.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model3.add(layers.Flatten())\n",
    "model3.add(layers.Dense(64, activation='relu'))\n",
    "model3.add(layers.Dense(num_classes_train, activation='softmax'))\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer= 'sgd',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "375a1820-ccb1-43cc-8dca-9d5a8de95d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:234 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_4 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 12288)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-4bdbf911631c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history3 = model3.fit(train_img, train_labels, \n\u001b[0m\u001b[1;32m      2\u001b[0m    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m    validation_data=(val_img, val_labels))\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:234 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_4 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 12288)\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(train_img, train_labels, \n",
    "   epochs=10,\n",
    "   batch_size=50, \n",
    "   validation_data=(val_img, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7d8d5-62d5-4f68-8133-da3c5a96fe98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d38b7952-e490-4e1c-8bc3-73e3e33c6c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        16416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 183,523\n",
      "Trainable params: 183,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a739b76f-5c7f-4ca5-b14c-ace4da4f80d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# loading training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/kaggle/input/intel-image-classification/seg_train/seg_train',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# loading testing data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "        '/kaggle/input/intel-image-classification/seg_test/seg_test',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# initialising sequential model and adding layers to it\n",
    "cnn = tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=48, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=48, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
    "\n",
    "# finally compile and train the cnn\n",
    "cnn.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "cnn.fit(x=train_generator, validation_data=test_generator, epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
