{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d30d481-615a-4798-b66f-9e8ec274e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,\\\n",
    "array_to_img,\\\n",
    "img_to_array,\\\n",
    "load_img\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import tools.visualizations as vis\n",
    "import tools.misc as misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ea002ef-0338-47ae-9730-1469de1bb1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloaded imports\n",
    "\n",
    "# pip install focal-loss\n",
    "from focal_loss import BinaryFocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "710c96cb-8620-4616-a62c-6d44671c0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path Constants\n",
    "TRAIN_PATH = 'data/split/train'\n",
    "VAL_PATH = 'data/split/val'\n",
    "TEST_PATH = 'data/split/test'\n",
    "\n",
    "# Image Processing Constants\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH = 64, 64\n",
    "\n",
    "# Change for test runs\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad8aa58-1d6e-4087-9156-d500556679cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model('models/model2.h5')\n",
    "model3 = load_model('models/model3.h5')\n",
    "model4 = load_model('models/model4.h5')\n",
    "model4_1 = load_model('models/model4_1.h5')\n",
    "model5 = load_model('models/model5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a26f7e4-6d4e-40e5-b64d-2c9836e63561",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'model2': model2,\n",
    "    'model3': model3,\n",
    "    'model4': model4,\n",
    "    'model4_1': model4_1,\n",
    "    'model5': model5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef731eb-b58a-4ffc-beb5-926076be2d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "-------------------------\n",
      "\tPNEUMONIA: 2564\n",
      "\tNORMAL: 950\n",
      "\n",
      "\tSUBTOTAL: 3514\n",
      "VAL\n",
      "-------------------------\n",
      "\tPNEUMONIA: 855\n",
      "\tNORMAL: 317\n",
      "\n",
      "\tSUBTOTAL: 1172\n",
      "TEST\n",
      "-------------------------\n",
      "\tPNEUMONIA: 854\n",
      "\tNORMAL: 316\n",
      "\n",
      "\tSUBTOTAL: 1170\n",
      "-------------------------\n",
      "TOTAL: 5856 files\n"
     ]
    }
   ],
   "source": [
    "# Call function to display counts and return dict of subtotals\n",
    "counts = misc.count_files([TRAIN_PATH, VAL_PATH, TEST_PATH])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40ea0ebc-e0dd-457d-9d67-432bb579b04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 3514, 'val': 1172, 'test': 1170}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc0cccd-cda7-4aaf-a704-66ddf8280c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DirectoryIterator parameters for flow_from_directory\n",
    "gen_params = {\n",
    "    'target_size': (64, 64),\n",
    "    'color_mode': 'grayscale',\n",
    "    'class_mode': 'binary',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fd36ed9-70a7-4dc3-b324-9923daddda44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3514 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Found 1170 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load \n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    TRAIN_PATH, \n",
    "    batch_size=counts['train'],\n",
    "    **gen_params\n",
    ")\n",
    "\n",
    "# Get all the data in the directory data/val (855+317 images), and reshape them\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    VAL_PATH, \n",
    "    batch_size=counts['val'],\n",
    "    **gen_params\n",
    ")\n",
    "\n",
    "# Get all the data in the directory data/test (854+316 images), and reshape them\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    batch_size=counts['test'],\n",
    "    **gen_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51a944e3-da48-4c0f-b816-b0fe053b7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the datasets\n",
    "train_images, train_labels = next(train_generator)\n",
    "val_images, val_labels = next(val_generator)\n",
    "test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed7648f6-96b8-44a5-a54f-7ba11cf714bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    # Save accuracy loss graphs and preview\n",
    "#     fig = vis.plot_loss_accuracy(model.history)\n",
    "#     plt.savefig(f'images/acc_loss/al_{model_name}')\n",
    "    \n",
    "    fig = vis.plot_confusion_matrices(model, train_images, test_images, train_labels, test_labels)\n",
    "    fig.suptitle(f'{model_name}')\n",
    "    plt.savefig(f'images/confusion_matrices/cm_{model_name}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28f794-ccac-42a2-a07b-06015473a6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "general"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
